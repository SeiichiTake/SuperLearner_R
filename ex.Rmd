## load R packages

```{r}
# How to install the SuperLearner R package:
install.packages("SuperLearner")
install.packages("arm")
install.packages("glmnet")
install.packages("earth")

# How to load SuperLearner R package (assuming it's already installed):
library(SuperLearner) # Version: 2.0-29
library(tidyverse)
library(ggplot2)
library(arm)
library(glmnet)
library(earth)
library(data.table)
```

At the end of this file, the R session information is provided, which includes the version numbers for all packages used in this file.

### EXAMPLE 1
Super learner (SL) specification based on guidelines

```{r}
set.seed(59)
n <- 50
X1 <- runif(n = n, min = -5, max = 5)
X2 <- runif(n = n, min = -5, max = 5)
X3 <- runif(n = n, min = -5, max = 5)
X4 <- runif(n = n, min = -5, max = 5)
Y <- 6 + 0.4*X1 - 0.36*(X2^2) + 0.1*(X1>0)*(X3^3) + rnorm(n)
d <- data.frame(Y, X1, X2, X3, X4)
```

**We will use data "d" in examples 1-4**

#### Part a
```{r}
### Use discrete SL (dSL) to predict outcome (Y) from predictors (X)
library_ex1 <- c("SL.mean", "SL.nnls", "SL.glm", "SL.glm.interaction",
                 "SL.bayesglm", "SL.glmnet", "SL.ridge", "SL.gam", "SL.earth")
set.seed(924)
sl_fit_ex1 <- SuperLearner(Y = d$Y, X = d[,-1], SL.library = library_ex1,
                           cvControl = list(V = 20))

### results
sl_fit_ex1
```

ensemble SL (eSL) is the default SL in the SuperLearner R package, with meta-learner "method.NNLS", and this eSL coefficients are column "Coef" in the table above that's output when sl_fit_1a is called. (We check its CV risk in example 1b.)

the dSL is the learner with the lowest CV risk. As shown in the table above, that's SL.earth_All, which is learner SL.earth with all covariates (i.e., SL.earth is not coupled with a screener) predictions for the dSL can be obtained from library.predict:

```{r}
pred_dSL_ex1 <- sl_fit_ex1$library.predict[, "SL.earth_All"]
```

#### Part b

Use dSL to predict Y from X, considering the ensemble SL (eSL) as an additional candidate for the dSL to select by examining its CV risk. 

NOTE: This requires the specifications in SuperLearner (above) and CV.SuperLearner (below) to be the same.

```{r}
set.seed(924)
cvsl_fit_ex1 <- CV.SuperLearner(Y = d$Y, X = d[,-1], SL.library = library_ex1,
                                cvControl = list(V = 20),
                                innerCvControl = list(list(V = 20)))
summary(cvsl_fit_ex1)
```

Column "Ave" is the average CV risk estimate across all folds. The dSL selects the learner with the smallest CV risk. As shown above, that's algorithm "SL.earth_All". 

Row with "Super Learner" algorithm is the CV performance of the eSL that was fit in example 1a, whose coefficients are provided in example 1a table. 

If the eSL, "Super Learner", had smallest "Ave" then it would be selected by the dSL and pred_dSL_ex1 could be changed as shown below: 

pred_dSL_ex1 <- sl_fit_ex1$SL.predict

**Note:** 

- The slight difference in CV risk results in examples 1a and 1b are due to variations in the cross-validation folds. 

- Algorithm "Discrete SL" in the table above can be ignored. It's not necessary to cross-validate the dSL; the dSL is just a copy of a learner that has already been cross-validated.

### EXAMPLE 2: Poor SL library specification

```{r}
library_ex2 <- c("SL.mean", "SL.nnls", "SL.glm", "SL.glm.interaction",
                 "SL.bayesglm", "SL.glmnet", "SL.ridge")
set.seed(924)
sl_fit_ex2 <- SuperLearner(Y = d$Y, X = d[, -1], SL.library = library_ex2,
                           cvControl = list(V = 20))
sl_fit_ex2
set.seed(924)
cvsl_fit_ex2 <- CV.SuperLearner(Y = d$Y, X = d[, -1], SL.library = library_ex2,
                                cvControl = list(V = 20),
                                innerCvControl = list(list(V = 20)))
summary(cvsl_fit_ex2)
```

### EXAMPLE 3: Poor cross-validation specification

```{r}
set.seed(924)
sl_fit_ex3 <- SuperLearner(Y = d$Y, X = d[, -1], SL.library = library_ex1,
                           cvControl = list(V = 2))
sl_fit_ex3
set.seed(924)
cvsl_fit_ex3 <- CV.SuperLearner(Y = d$Y, X = d[,-1], SL.library = library_ex1,
                                cvControl = list(V = 2),
                                innerCvControl = list(list(V = 2)))
summary(cvsl_fit_ex3)
```

### EXAMPLE 4: Super learner (SL) specification for rare binary outcome based on guidelines

We'll draw on the same simulation as examples 1-3 but this time we will simulate a rare binary outcome. We do this by specifying an arbitrary cutoff, -8.5, that is close to the minimum value of Y.

```{r}
set.seed(59)
n <- 5000
X1 <- runif(n = n, min = -5, max = 5)
X2 <- runif(n = n, min = -5, max = 5)
X3 <- runif(n = n, min = -5, max = 5)
X4 <- runif(n = n, min = -5, max = 5)
Y <- as.numeric(6 + 0.4*X1 - 0.36*(X2^2) + 0.1*(X1>0)*(X3^3) + rnorm(n) < -8.75)
d_binaryY <- data.frame(Y, X1, X2, X3, X4)

library_ex4 <- c("SL.mean", "SL.glm", "SL.glm.interaction", "SL.bayesglm", 
                 "SL.glmnet", "SL.gam", "SL.earth")
set.seed(924)
sl_fit_ex4 <- SuperLearner(
  Y = d_binaryY[, 1], X = d_binaryY[, -1], SL.library = library_ex4, 
  method = "method.NNloglik", family = binomial(),
  cvControl = list(V = 20, stratifyCV = TRUE)
)
sl_fit_ex4

set.seed(924)
cvsl_fit_ex4 <- CV.SuperLearner(
  Y = d_binaryY[, 1], X = d_binaryY[, -1], SL.library = library_ex4,
  method = "method.NNloglik", family = binomial(),
  cvControl = list(V = 20, stratifyCV = TRUE),
  innerCvControl = list(list(V = 20, stratifyCV = TRUE))
)
summary(cvsl_fit_ex4)
```

### EXAMPLE 5: Super learner (SL) specification for rare binary outcome with poor cross-validation specification

```{r}
set.seed(924)
sl_fit_ex5 <- SuperLearner(
  Y = d_binaryY[, 1], X = d_binaryY[, -1], SL.library = library_ex4, 
  method = "method.NNloglik", family = binomial(),
  cvControl = list(V = 5)
)
sl_fit_ex5
set.seed(924)
cvsl_fit_ex5 <- CV.SuperLearner(
  Y = d_binaryY[, 1], X = d_binaryY[, -1], SL.library = library_ex4,
  method = "method.NNloglik", family = binomial(),
  cvControl = list(V = 5),
  innerCvControl = list(list(V = 5))
)
summary(cvsl_fit_ex5)
```

### EXAMPLE 6 ANALYTIC DATAET PREPROCESSING R CODE
The file "IST dataset, corrected (csv)" was first downloaded from the database (https://datashare.ed.ac.uk/handle/10283/124) and stored in the user's "Downloads" folder.

```{r}
d <- read.csv("ije-2022-04-0407-File009.csv")
```

set 14-day mortality to "N" if recurrent stroke occurred after 14 days

```{r}
d$DDEAD <- as.character(d$DDEAD)
d$DDEAD[(d$DDEAD != "N" & d$DDEADD > 14)] <- "N"
```

specify covariates and outcome and filter data to include relevant columns

```{r}
X <- c("RDELAY", "RCONSC", "SEX", "AGE", "RSLEEP", "RATRIAL", "RCT",
       "RVISINF", "RHEP24", "RASP3", "RSBP", "RDEF1", "RDEF2",
       "RDEF3", "RDEF4", "RDEF5", "RDEF6", "RDEF7", "RDEF8", "STYPE",
       "RXHEP", "RXASP")
Y <- "DDEAD"
d <- dplyr::select(d, all_of(c(X, Y)))
```

find missing data
```{r}
d[d == ""] <- NA
d[d == "NULL"] <- NA
d[d == " "] <- NA
d[d == "  "] <- NA
d[d == "[]"] <- NA
colSums(is.na(d))
summary(d)
```

create binary indicator columns denoting missingness and impute with U

```{r}
all.equal(is.na(d$RATRIAL), is.na(d$RASP3)) # missingness pattern is the same!
d$MISSING_RATRIAL_RASP3 <- rep(0, nrow(d))
d$MISSING_RATRIAL_RASP3[is.na(d$RATRIAL)] <- 1

d$MISSING_RHEP24 <- rep(0, nrow(d))
d$MISSING_RHEP24[is.na(d$RHEP24)] <- 1
d$RATRIAL[is.na(d$RATRIAL)] <- "U"
d$RASP3[is.na(d$RASP3)] <- "U"
d$RHEP24[is.na(d$RHEP24)] <- "U"
```

remove the observations with missing outcome (a negligible proportion)

```{r}
d <- d[!(is.na(d$DDEAD) | d$DDEAD == "U"),]
d$DDEAD[d$DDEAD == "Y"] <- 1 # change “Y” (14-day morality occurred) to 1
d$DDEAD[d$DDEAD == "N"] <- 0 # change “N” (14-day morality didn't occur) to 0
write.csv(d, file = "data_example6.csv", row.names = FALSE) 
```

### EXAMPLE 7 ANALYTIC DATASET PREPROCESSING R CODE 

File "Additional File 1: Data set from acupuncture headache trial (XLS 254 KB)" 
was first downloaded from Vickers AJ. Whose data set is it anyway? Sharing 
raw data from randomized trials. Trials. 2006 Dec;7(1):1-6. 
https://doi.org/10.1186/1745-6215-7-15. This downloaded data was stored in 
the user's "Downloads" folder with name "13063_2006_152_MOESM1_ESM.xls".

```{r}
d <- read_csv("13063_2006_152_MOESM1_ESM.csv")
data.table::setDT(d)
```

define nodes in observed data

- W: baseline covariates, variables measured before or at assignment of A

- A: treatment, randomization to acupuncture (A = 1) or usual care (A = 0)

- Delta: missingness indicator (if Y observed Delta=1 and if not Delta=0)

- Y: outcome, 12-month headache score

```{r}
W <- c("age", "sex", "migraine", "chronicity", "pk1", "f1", "pf1", "rlp1",
       "rle1", "ef1", "ewb1", "sf1", "p1", "gen1", "hc1", "painmedspk1",
       "prophylacticdose1","prophmqs1","allmedsbaseline")
A <- "group" # treatment, randomization to acupuncture (A = 1) or usual care (A = 0)
Delta <- "completer" # missingness indicator (if Y observed Delta=1 and if not Delta=0)
Y <- "pk5" # Y: outcome, 12-month headache score
```

subset data to nodes of interest

```{r}
d <- d[, c(Y, Delta, A, W), with = FALSE]
colnames(d)[1:3] <- c("Y", "Delta", "A")
```

fix prophylacticdose1 column: it should be 0, not NA, when prophmqs1 = 0

```{r}
d$prophylacticdose1 <- ifelse(d$prophmqs1 == 0, 0, d$prophylacticdose1)
```

examine missingness of all data

```{r}
colSums(is.na(d))
```

create indicators of whether W values are missing before imputing them

ef1, ewb1, sf1, gen1 and hc1 missingness in just one row, and it's the same

```{r}
d[which(is.na(d$hc1)),] 
d$missing_ef1_ewb1_sf1_gen1_hc1 <- ifelse(is.na(d$ef1), 1, 0)
d$missing_p1 <- ifelse(is.na(d$p1), 1, 0)
d$missing_rle1 <- ifelse(is.na(d$rle1), 1, 0)
d$missing_pf1 <- ifelse(is.na(d$pf1), 1, 0)
d$missing_rlp1 <- ifelse(is.na(d$rlp1), 1, 0)
```

imputation 

all W with NA are continuous, we impute with median

```{r}
imputedW <- apply(d[ , -c("Y", "Delta", "A"), with = F], 2, function(W){
  ifelse(is.na(W), median(W, na.rm = T), W)
})
sum(is.na(imputedW)) == 0
```

put it all together

```{r}
d <- data.table(Y = d$Y, Delta = d$Delta, A = d$A, imputedW)
write.csv(d, file = "data_example7.csv", row.names = FALSE)
```